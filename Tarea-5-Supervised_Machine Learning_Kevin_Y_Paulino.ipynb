{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro ML SUP en BD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de la sesión Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SparkSession\n",
    "import findspark\n",
    "findspark.init('C:/Spark/spark-2.4.4-bin-hadoop2.7')\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, udf \n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el spark session object, llamarle \"supervised_ml\"\n",
    "\n",
    "supervised_ml=SparkSession.builder.appName('App_supervised_ml').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos, archivo *Linear_regression_dataset.csv*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "df=supervised_ml.read.csv(\"Linear_regression_dataset.csv\",header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se invocan las librerias correcpondientes a **LinearRegression**, asi como las de OneHotEncoder, StringIndexer, VectorAssembler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion de libs y operaciones\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se visualizan algunos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 6)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los primeros 10 datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+-----+-----+\n",
      "|var_1|var_2|var_3|var_4|var_5|label|\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  734|  688|   81|0.328|0.259|0.418|\n",
      "|  700|  600|   94| 0.32|0.247|0.389|\n",
      "|  712|  705|   93|0.311|0.247|0.417|\n",
      "|  734|  806|   69|0.315| 0.26|0.415|\n",
      "|  613|  759|   61|0.302| 0.24|0.378|\n",
      "|  748|  676|   85|0.318|0.255|0.422|\n",
      "|  669|  588|   97|0.315|0.251|0.411|\n",
      "|  667|  845|   68|0.324|0.251|0.381|\n",
      "|  758|  890|   64| 0.33|0.274|0.436|\n",
      "|  726|  670|   88|0.335|0.268|0.422|\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# primeros 10 datos\n",
    "\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un solo vector con todos los features i.e 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', a este le llamaremos \"features\" y como salida colocamos a 'label':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[734.0,688.0,81.0...|0.418|\n",
      "|[700.0,600.0,94.0...|0.389|\n",
      "|[712.0,705.0,93.0...|0.417|\n",
      "|[734.0,806.0,69.0...|0.415|\n",
      "|[613.0,759.0,61.0...|0.378|\n",
      "|[748.0,676.0,85.0...|0.422|\n",
      "|[669.0,588.0,97.0...|0.411|\n",
      "|[667.0,845.0,68.0...|0.381|\n",
      "|[758.0,890.0,64.0...|0.436|\n",
      "|[726.0,670.0,88.0...|0.422|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vector Ensamblador\n",
    "\n",
    "\n",
    "#vectorAssembler = VectorAssembler(inputCols = ['var_1', 'var_2', 'var_3', 'var_4', 'var_5'], outputCol = 'features')\n",
    "#vhouse_df = vectorAssembler.transform(df)\n",
    "#vhouse_df = vhouse_df.select(['features', 'label'])\n",
    "#vhouse_df.show(3)\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['var_1', 'var_2', 'var_3', 'var_4', 'var_5'], outputCol = 'features')\n",
    "vdf = vectorAssembler.transform(df)\n",
    "vdf = vdf.select(['features', 'label'])\n",
    "vdf.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[734.0,688.0,81.0...|0.418|\n",
      "|[700.0,600.0,94.0...|0.389|\n",
      "|[712.0,705.0,93.0...|0.417|\n",
      "|[734.0,806.0,69.0...|0.415|\n",
      "|[613.0,759.0,61.0...|0.378|\n",
      "|[748.0,676.0,85.0...|0.422|\n",
      "|[669.0,588.0,97.0...|0.411|\n",
      "|[667.0,845.0,68.0...|0.381|\n",
      "|[758.0,890.0,64.0...|0.436|\n",
      "|[726.0,670.0,88.0...|0.422|\n",
      "|[583.0,794.0,55.0...|0.371|\n",
      "|[676.0,746.0,72.0...|  0.4|\n",
      "|[767.0,699.0,89.0...|0.433|\n",
      "|[637.0,597.0,86.0...|0.374|\n",
      "|[609.0,724.0,69.0...|0.382|\n",
      "|[776.0,733.0,83.0...|0.437|\n",
      "|[701.0,832.0,66.0...| 0.39|\n",
      "|[650.0,709.0,74.0...|0.386|\n",
      "|[804.0,668.0,95.0...|0.453|\n",
      "|[713.0,614.0,94.0...|0.404|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visulizacion de vector ensamblado compuesto por features y label\n",
    "\n",
    "vdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos a continuación el set de datos en 75% training y 25% testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train Dataset : 873\n",
      "Size of test Dataset : 359\n"
     ]
    }
   ],
   "source": [
    "# Particion del data set\n",
    "\n",
    "splits = vdf.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "\n",
    "print(f\"Size of train Dataset : {train_df.count()}\" )\n",
    "print(f\"Size of test Dataset : {test_df.count()}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor Lineal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='label', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo de regresión lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.0]\n",
      "Intercept: 0.39681557846506255\n"
     ]
    }
   ],
   "source": [
    "# Fit the model, le llamamos lr_model\n",
    "\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataframe de prediciones (*predictions_df*) a partir del modelo de entrenamiento y el conjunto de datos test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = lr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el contenido de *predictions_df*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|label|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|[468.0,746.0,52.0...|0.329|0.39681557846506255|\n",
      "|[498.0,615.0,67.0...|0.318|0.39681557846506255|\n",
      "|[511.0,576.0,76.0...|0.329|0.39681557846506255|\n",
      "|[522.0,621.0,72.0...|0.317|0.39681557846506255|\n",
      "|[533.0,660.0,62.0...| 0.33|0.39681557846506255|\n",
      "|[541.0,830.0,60.0...| 0.33|0.39681557846506255|\n",
      "|[552.0,683.0,71.0...|0.335|0.39681557846506255|\n",
      "|[556.0,675.0,67.0...|0.348|0.39681557846506255|\n",
      "|[559.0,613.0,75.0...|0.359|0.39681557846506255|\n",
      "|[569.0,544.0,82.0...|0.343|0.39681557846506255|\n",
      "|[569.0,776.0,53.0...|0.348|0.39681557846506255|\n",
      "|[570.0,662.0,73.0...|0.337|0.39681557846506255|\n",
      "|[573.0,717.0,62.0...|0.345|0.39681557846506255|\n",
      "|[575.0,864.0,55.0...|0.379|0.39681557846506255|\n",
      "|[578.0,733.0,62.0...|0.348|0.39681557846506255|\n",
      "|[579.0,655.0,71.0...|0.357|0.39681557846506255|\n",
      "|[581.0,724.0,64.0...|0.346|0.39681557846506255|\n",
      "|[585.0,755.0,59.0...|0.358|0.39681557846506255|\n",
      "|[587.0,722.0,70.0...| 0.37|0.39681557846506255|\n",
      "|[587.0,866.0,57.0...|0.373|0.39681557846506255|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visulizacion de predictions_df\n",
    "\n",
    "predictions_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, evaluamos el modelo de Regresión Lineal, con los datos de TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+\n",
      "|         prediction|label|            features|\n",
      "+-------------------+-----+--------------------+\n",
      "|0.39681557846506255|0.329|[468.0,746.0,52.0...|\n",
      "|0.39681557846506255|0.318|[498.0,615.0,67.0...|\n",
      "|0.39681557846506255|0.329|[511.0,576.0,76.0...|\n",
      "|0.39681557846506255|0.317|[522.0,621.0,72.0...|\n",
      "|0.39681557846506255| 0.33|[533.0,660.0,62.0...|\n",
      "+-------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluacion del modelo, le llamaremos model_predictions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "model_predictions = lr_model.transform(test_df)\n",
    "\n",
    "model_predictions.select(\"prediction\",\"label\",\"features\").show(5)\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"label\",metricName=\"r2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el valor de R2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = -0.00313915\n"
     ]
    }
   ],
   "source": [
    "# valor de R2\n",
    "\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(model_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el valor del meanSquaredError:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.032277\n"
     ]
    }
   ],
   "source": [
    "# valor del meanSquaredError\n",
    "\n",
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión con Árboles de Decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la librería *DecisionTreeRegressor*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor DT, le llamaremos *dec_tree*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_tree\n",
    "\n",
    "dec_tree = DecisionTreeRegressor(featuresCol ='features', labelCol = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, le llamaremos dec_tree_model\n",
    "\n",
    "dec_tree_model = dec_tree.fit(train_df)\n",
    "dt_predictions = dec_tree_model.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuánto es la profundidad máxima por defecto, de este algoritmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos las *featureImportances*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.9703, 1: 0.0099, 2: 0.0031, 3: 0.006, 4: 0.0108})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.0136859\n"
     ]
    }
   ],
   "source": [
    "# Make predictions, le llamaremos model_predictions \n",
    "\n",
    "model_predictions = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = model_predictions.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionEvaluator_4e9495743252"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizamos\n",
    "model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el **RegressionEvaluator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionEvaluator_4151334edaa9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Evaluator\n",
    "\n",
    "RegressionEvaluator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando *RegressionEvaluator* calculamos e imprimimos el valor de las metricas R2 y RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RegressionEvaluator' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9f4a9eb37612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# R2 value of the model on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdt_evaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdt_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_evaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The r-square value of DecisionTreeRegressor is {dt_r2}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Spark/spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Spark/spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \"\"\"\n\u001b[0;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RegressionEvaluator' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "# R2 value of the model on test data \n",
    "dt_evaluator = RegressionEvaluator(metricName='r2')\n",
    "dt_r2 = dt_evaluator.evaluate(model_predictions)\n",
    "print(f'The r-square value of DecisionTreeRegressor is {dt_r2}')\n",
    "\n",
    "# RMSE value of the model on test data \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos a *RandomForestRegressor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresor \n",
    "rf = RandomForestRegressor(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, le llamaremos rf_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos las *featureImportances*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importances \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos el numero de arboles (Num of Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de Trees\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con los datos de entrenamiento, le llamaremos model_predictions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos los valores del *model_predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando *RegressionEvaluator* calculamos e imprimimos el valor de las metricas R2 y RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 value of the model on test data \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RMSE value of the model on test data \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Boosted Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos a GBTRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor GBTR, le llamaremos gbt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regresor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, le llamaremos gbt_model\n",
    "\n",
    "gbt_model = gbt.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos las featureImportances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.289, 1: 0.178, 2: 0.2122, 3: 0.1366, 4: 0.1842})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importances\n",
    "\n",
    "gbt_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con los datos de entrenamiento, le llamaremos model_predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+\n",
      "|         prediction|label|            features|\n",
      "+-------------------+-----+--------------------+\n",
      "| 0.3229654363045081|0.319|[470.0,509.0,76.0...|\n",
      "|0.32130134823534245|0.318|[498.0,615.0,67.0...|\n",
      "| 0.3237376066332866|0.325|[498.0,672.0,61.0...|\n",
      "|0.33176672221789794|0.317|[510.0,588.0,72.0...|\n",
      "| 0.3237376066332866|0.339|[513.0,698.0,61.0...|\n",
      "+-------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model_predictions = gbt_model.transform(test_df)\n",
    "model_predictions.select('prediction', 'label', 'features').show(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos los valores del *model_predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|label|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|[470.0,509.0,76.0...|0.319| 0.3229654363045081|\n",
      "|[498.0,615.0,67.0...|0.318|0.32130134823534245|\n",
      "|[498.0,672.0,61.0...|0.325| 0.3237376066332866|\n",
      "|[510.0,588.0,72.0...|0.317|0.33176672221789794|\n",
      "|[513.0,698.0,61.0...|0.339| 0.3237376066332866|\n",
      "|[527.0,569.0,75.0...|0.341| 0.3323506642270911|\n",
      "|[528.0,652.0,71.0...|0.319|0.32996615015463343|\n",
      "|[531.0,491.0,89.0...| 0.32|0.32658471665728805|\n",
      "|[533.0,660.0,62.0...| 0.33| 0.3241382055119172|\n",
      "|[534.0,609.0,69.0...|0.329|0.33176672221789794|\n",
      "|[536.0,531.0,83.0...|0.318| 0.3237840499906214|\n",
      "|[541.0,830.0,60.0...| 0.33|0.32471341450908076|\n",
      "|[543.0,615.0,76.0...|0.333|  0.333599944561744|\n",
      "|[543.0,747.0,60.0...|0.342| 0.3250048849062326|\n",
      "|[550.0,631.0,76.0...|0.318| 0.3317993724984795|\n",
      "|[550.0,789.0,54.0...|0.359| 0.3253986302674275|\n",
      "|[552.0,683.0,71.0...|0.335|0.35170174482997885|\n",
      "|[556.0,674.0,62.0...|0.348| 0.3237376066332866|\n",
      "|[556.0,675.0,67.0...|0.348| 0.3237376066332866|\n",
      "|[558.0,688.0,67.0...| 0.35| 0.3237376066332866|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show \n",
    "\n",
    "model_predictions.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando RegressionEvaluator calculamos e imprimimos el valor de las metricas R2 y RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.0140442\n"
     ]
    }
   ],
   "source": [
    " #Select (prediction, true label) and compute test error\n",
    "# R2 value of the model on test data \n",
    "\n",
    " gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "\n",
    "# RMSE value of the model on test data \n",
    "\n",
    "rmse = gbt_evaluator.evaluate(model_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exploracion de datos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset https://archive.ics.uci.edu/ml/datasets/Bank+Marketing \n",
    "\n",
    "Indique a grandes razgos de que se trata este dataset:\n",
    "\n",
    "El dataet contiene datos relacionados con campañas publicitarias realizada vía telefónica, para una institución bancaria portuguesa. El objetivo principal de la clasificación es predecir si el cliente se suscribe o no a depósitos a plazo (variable target_class).\n",
    "\n",
    "En el link dice que contiene  17 atributos, sin embargo al ver el dataset tiene 20, algunos de ellos son: edad, tipo de trabajo, estado civil, nivel de educación, tiene crédito en incumplimiento, tiene préstamo de vivienda, tiene préstamo personal, tipo de contacto, último mes que se le contacto, día de la semana del último contacto, duración en segundos del último contacto y otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos, archivo bank_data.csv:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv Dataset \n",
    "spark=SparkSession.builder.appName('App_llamadasBancarias').getOrCreate()\n",
    "\n",
    "df=spark.read.csv('bank_data.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine la cantidad de datos en el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros:  41188  y la cantidad de columnas:  21\n"
     ]
    }
   ],
   "source": [
    "#number of records\n",
    "\n",
    "\n",
    "print(\"Cantidad de registros: \", df.count(), \" y la cantidad de columnas: \", len(df.columns)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A que dato corresponde cada columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, age: string, job: string, marital: string, education: string, default: string, housing: string, loan: string, contact: string, month: string, day_of_week: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, emp.var.rate: string, cons.price.idx: string, cons.conf.idx: string, euribor3m: string, nr.employed: string, target_class: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns values \n",
    "#en esta no estoy clara que desea que ejecutemos, así que se incluye: describe, dtypes y take\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('month', 'string'),\n",
       " ('day_of_week', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('emp.var.rate', 'double'),\n",
       " ('cons.price.idx', 'double'),\n",
       " ('cons.conf.idx', 'double'),\n",
       " ('euribor3m', 'double'),\n",
       " ('nr.employed', 'double'),\n",
       " ('target_class', 'string')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=56, job='housemaid', marital='married', education='basic.4y', default='no', housing='no', loan='no', contact='telephone', month='may', day_of_week='mon', duration=261, campaign=1, pdays=999, previous=0, poutcome='nonexistent', emp.var.rate=1.1, cons.price.idx=93.994, cons.conf.idx=-36.4, euribor3m=4.857, nr.employed=5191.0, target_class='no')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima el Schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp.var.rate: double (nullable = true)\n",
      " |-- cons.price.idx: double (nullable = true)\n",
      " |-- cons.conf.idx: double (nullable = true)\n",
      " |-- euribor3m: double (nullable = true)\n",
      " |-- nr.employed: double (nullable = true)\n",
      " |-- target_class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataype of input data - Schema\n",
    "\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la salida, como es la distrubución de clases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|target_class|count|\n",
      "+------------+-----+\n",
      "|          no|36548|\n",
      "|         yes| 4640|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YES/NO Class Distribution\n",
    " \n",
    "df.groupBy('target_class').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una tarea típica, resulta de convertir los valores binarios en 1 y 0, usando como referencia \"label\", convierta los no/yes en 0/1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import regexp_replace,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingrese acá la instrucción: \n",
    "\n",
    "df_Nuevo = df.withColumn('target_class', regexp_replace('target_class', 'no', '0'))\n",
    "df_Nuevo = df_Nuevo.withColumn('target_class', regexp_replace('target_class', 'yes', '1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|target_class|count|\n",
      "+------------+-----+\n",
      "|           0|36548|\n",
      "|           1| 4640|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New 1/0 Class Distribution\n",
    " \n",
    "df_Nuevo.groupBy('target_class').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta un ejercicio de Deep Learning para su revisión..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import udf, StringType\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos la sesion SPARK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('deep_learning').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('dl_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos la columna TARGET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed('Orders_Normalized', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos lo datos en Train, Validation y Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test  = data.randomSplit([0.7, 0.2, 0.1], 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [item[0] for item in data.dtypes if item[1].startswith('string')]\n",
    "numeric_columns = [item[0] for item in data.dtypes if item[1].startswith('double')]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol='{0}_index'.format(column)) for column in categorical_columns]\n",
    "\n",
    "featuresCreator = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numeric_columns, outputCol=\"features\")\n",
    "\n",
    "layers = [len(featuresCreator.getInputCols()), 4, 2, 2]\n",
    "\n",
    "classifier = MultilayerPerceptronClassifier(labelCol='label', featuresCol='features', maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [featuresCreator, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validamos y Evaluamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_df = model.transform(train)\n",
    "validation_output_df = model.transform(validation)\n",
    "test_output_df = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llevamos a cabo, algunas predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_output_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c66f00cd2fe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_predictionAndLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_output_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"label\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvalidation_predictionAndLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_output_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"label\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_predictionAndLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_output_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"label\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'weightedPrecision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weightedRecall'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_output_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_predictionAndLabels = train_output_df.select(\"prediction\", \"label\")\n",
    "validation_predictionAndLabels = validation_output_df.select(\"prediction\", \"label\")\n",
    "test_predictionAndLabels = test_output_df.select(\"prediction\", \"label\")\n",
    "\n",
    "metrics = ['weightedPrecision', 'weightedRecall', 'accuracy']\n",
    "\n",
    "for metric in metrics:\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=metric)\n",
    "    print('Train ' + metric + ' = ' + str(evaluator.evaluate(train_predictionAndLabels)))\n",
    "    print('Validation ' + metric + ' = ' + str(evaluator.evaluate(validation_predictionAndLabels)))\n",
    "    print('Test ' + metric + ' = ' + str(evaluator.evaluate(test_predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede mejorar el test accuracy del modelo variando alguno de los hyperparametros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
